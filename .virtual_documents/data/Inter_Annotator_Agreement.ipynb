import csv
import pandas as pd
import numpy as np 
import matplotlib.pyplot as plt
import json
import itertools
from sklearn.metrics import cohen_kappa_score, confusion_matrix, ConfusionMatrixDisplay
import os


def create_dataframe_from_jsonl(file_name, label_prefix):
    # Read the JSONL file line by line
    data = []
    with open(file_name, 'r') as file:
        for line in file:
            json_data = json.loads(line)
            #print(json_data)
            pmid = json_data['pmid']
            #accept = json_data['accept'][0]
            accept = json_data['accept'][0] if json_data['accept'] else "label missing"
            label_title = '{}_label'.format(label_prefix)
            data.append({'pmid': pmid, label_title: accept})

    # Create a DataFrame
    df = pd.DataFrame(data)
    
    return df



def visualize_label_frequencies(df, annotator_name, save_path='./prodigy/viz'):
    # Mapping labels to numerical values
    labels = ["Human-systematic-review", "Human-RCT-drug-intervention", "Human-RCT-non-drug-intervention", "Human-RCT-non-intervention", "Human-case-report", "Human-non-RCT-drug-intervention", "Human-non-RCT-non-drug-intervention", "Animal-systematic-review", "Animal-drug-intervention", "Animal-non-drug-intervention", "Animal-other", "Non-systematic-review", "In-vitro-study", "Clinical-study-protocol", "Remaining"]

    label_to_numerical = {label: i for i, label in enumerate(labels)}

    # Create a new column with mapped values
    label_title = '{}_label'.format(annotator_name)

    # Plotting the frequency of each label with inverted y-axis and values on bars
    plt.figure(figsize=(10, 6))
    ax = df[label_title].value_counts().sort_values(ascending=True).plot(kind='barh', color='skyblue')
    plt.title(f'Label Frequency by Annotator {annotator_name}')
    plt.xlabel('Frequency')
    plt.ylabel('Label')

    # Display the frequency values on the bars
    for i, value in enumerate(df[label_title].value_counts().sort_values(ascending=True)):
        ax.text(value, i, str(value), va='center', ha='left')

    # Ensure the 'viz' folder exists
    os.makedirs(save_path, exist_ok=True)

    # Save the plot as an image
    save_filename = os.path.join(save_path, f'label_frequency_{annotator_name}_{len(df)}.png')
    plt.savefig(save_filename, bbox_inches='tight')
    plt.show()


labels = ["Human-systematic-review", "Human-RCT-drug-intervention", "Human-RCT-non-drug-intervention", "Human-RCT-non-intervention", "Human-case-report", "Human-non-RCT-drug-intervention", "Human-non-RCT-non-drug-intervention", "Animal-systematic-review", "Animal-drug-intervention", "Animal-non-drug-intervention", "Animal-other", "Non-systematic-review", "In-vitro-study", "Clinical-study-protocol", "Remaining"]

label_to_numerical = {label: i for i, label in enumerate(labels)}
label_to_numerical["label missing"] = -1


print(label_to_numerical)


annotator1 = "shirin"
annotator2 = "ben"





#file_name = './prodigy/annotated_output/pilot_500_pubmed_abstracts_shirin_test_review.jsonl'
file_name = './prodigy/annotated_output/pilot_2_200_pubmed_abstracts_shirin.jsonl'

result_df_1 = create_dataframe_from_jsonl(file_name, annotator1)
# label column names
label_title = '{}_label'.format(annotator1)
numeric_label_title = 'annotations_array_numeric_{}'.format(annotator1)
# Create a new column with mapped values
result_df_1[numeric_label_title] = result_df_1[label_title].map(label_to_numerical)


result_df_1


visualize_label_frequencies(result_df_1, annotator_name=annotator1)





#file_name = './prodigy/annotated_output/pubmed_abstracts_pilot_ben.jsonl'
file_name = './prodigy/annotated_output/pilot_2_200_pubmed_abstracts_ben.jsonl'

result_df_2 = create_dataframe_from_jsonl(file_name, annotator2)
# label column names
label_title = '{}_label'.format(annotator2)
numeric_label_title = 'annotations_array_numeric_{}'.format(annotator2)
# Create a new column with mapped values
result_df_2[numeric_label_title] = result_df_2[label_title].map(label_to_numerical)


result_df_2.head()


visualize_label_frequencies(result_df_2, annotator_name=annotator2)





def calculate_cohen_kappa_from_cfm_with_ci(confusion, print_result=False):
    # COPIED FROM SKLEARN METRICS
    # Sample size
    n = np.sum(confusion)
    # Number of classes
    n_classes = confusion.shape[0]
    # Expected matrix
    sum0 = np.sum(confusion, axis=0)
    sum1 = np.sum(confusion, axis=1)
    expected = np.outer(sum0, sum1) / np.sum(sum0)

    # Calculate p_o (the observed proportionate agreement) and
    # p_e (the probability of random agreement)
    identity = np.identity(n_classes)
    p_o = np.sum((identity * confusion) / n)
    p_e = np.sum((identity * expected) / n)
    # Calculate Cohen's kappa
    kappa = (p_o - p_e) / (1 - p_e)
    # Confidence intervals
    se = np.sqrt((p_o * (1 - p_o)) / (n * (1 - p_e) ** 2))
    ci = 1.96 * se * 2
    ci_boundary_limits = 1.96 * se
    lower = kappa - ci_boundary_limits
    upper = kappa + ci_boundary_limits

    if print_result:
        print(
            f'p_o = {p_o}, p_e = {p_e}, lower={lower:.2f}, kappa = {kappa:.2f}, upper={upper:.2f}, boundary = {ci_boundary_limits:.3f}\n',
            f'standard error = {se:.3f}\n',
            f'lower confidence interval = {lower:.3f}\n',
            f'kappa score = {kappa:.3f}\n',
            f'upper confidence interval = {upper:.3f}', sep=''
        )

    return kappa, ci_boundary_limits


def calculate_overall_cohen_kappa_with_ci(df, annotators, single_annotatoins_case=False):
    # see implementation and explanation in https://rowannicholls.github.io/python/statistics/agreement/cohens_kappa.html

    for annotator1, annotator2 in itertools.combinations(annotators, 2):
        annotations1 = df[f'annotations_array_numeric_{annotator1}']  # ast.literal_eval(
        annotations2 = df[f'annotations_array_numeric_{annotator2}']
        
        if single_annotatoins_case:
            combined_array_1 = annotations1.values
            combined_array_2 = annotations2.values
        else:
            # Combine all rows into a single array
            combined_array_1 = np.concatenate([eval(row) for row in annotations1]).tolist()
            combined_array_2 = np.concatenate([eval(row) for row in annotations2]).tolist()

        confusion = confusion_matrix(combined_array_1, combined_array_2)
        print(f"Cohen-Kappa with Confidence intervals {annotator1} vs {annotator2}")
        calculate_cohen_kappa_from_cfm_with_ci(confusion, print_result=True)


annotators = [annotator1, annotator2]
annotators


# Merge the two DataFrames on the 'pmid' column
result_df = pd.merge(result_df_1, result_df_2, on='pmid')

# Display the result DataFrame
result_df.shape


#result_df['annotations_array_numeric_shirin'] = result_df['annotations_array_numeric_shirin'].fillna(-1).astype(int)



result_df.head()


calculate_overall_cohen_kappa_with_ci(result_df, annotators, single_annotatoins_case=True)


calculate_overall_cohen_kappa_with_ci(result_df, annotators, single_annotatoins_case=True)



